#
# Cassandra Config
#

com.brighttag.sc2cc.cluster.name=SampleCluster
com.brighttag.sc2cc.cluster.hosts=127.0.0.1:9160
com.brighttag.sc2cc.keyspace.name=cookiehub

# Existing Column Family (Super)
com.brighttag.sc2cc.column.family.old=vendordata

# New Column Family (Composite)
# This CF must exist before you can run sc2cc
com.brighttag.sc2cc.column.family.new=vendordata2

#
# Transformer Tuning
#
# These numbers will vary by your schema and machine. The idea is
# to max out your CPU while avoiding an OutOfMemoryError.
#

# For a typical SuperRow such as
# 
# RowKey: 776e9992-d9b2-44e1-9069-389bdbe1bd4a
# => (super_column=bs,
#      (column=uid, value=9E817EF6-F421-11DF-BE06-E95BE2862FEF, timestamp=1334844272626000, ttl=31536000))
# => (super_column=hl,
#      (column=uid, value=03f0ac96-58ba-49f6-ade2-cbb04edb2c81, timestamp=1334844272197000, ttl=31536000))
# 
# uid column: (3*2 + 2) + 1 + 8 + (36*2 + 4) = 93 bytes
# super column with one uid column: (93*1) + (2*2 + 2) + 4 + 8 + 4 = 115 bytes
# super row with two super columns: (115*2) + (36*2 + 2) = 304 bytes
# 
# Since this is the size as serialized on disk, let's double it to account for the various in-
# memory structures used to hold collections. Thus, we'll assume avgSuperRowSizeBytes ~ 1kb.
# 
# We have on the order of
# {@code ((threadNum + queueSize + 1) x taskSize + rowCount) x avgSuperRowSizeBytes}
# bytes in memory. To avoid an OutOfMemoryError, this should be less than the Java heap size.
# 
# With threadNum=5, queueSize=10, taskSize=500, rowCount=500, avgSuperRowSizeBytes=1000,
# we have ((5+10+1)*500+500)*1000 = 8,500,000 bytes, or 8.5MB.

# The number of worker threads used to transform the block of rows and write to the new column family
com.brighttag.sc2cc.transformer.thread.num=5

# The number of rows handed to a single rewrite thread.
com.brighttag.sc2cc.transformer.task.size=500

# The number of tasks queued in the executor. Tasks executed by main thread after threshold reached.
com.brighttag.sc2cc.transformer.queue.size=10